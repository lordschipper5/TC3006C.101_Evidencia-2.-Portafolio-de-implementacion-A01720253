{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 2 Uso de framework o biblioteca de aprendizaje máquina para la implementación de una solución. (Portafolio Implementación)\n",
        "\n",
        "En este proyecto, se propone crear un modelo de clasificación utilizando el algoritmo Random Forest. Para llevar a cabo este proceso, optamos por utilizar Python como lenguaje de programación y el framework de sklearn, ya que es conocido por su facilidad de uso y una amplia gama de bibliotecas disponibles para la manipulación y análisis de datos.\n",
        "\n",
        "Se utilizara el dataset de **Titanic** donde, **se predece si una persona sobrevivió o no al desastre del Titanic**. Para conocer más sobre este proyecto se puede consultar el siguiente link: https://www.kaggle.com/competitions/titanic\n",
        "\n",
        "El proceso estara documentado con comentarios en el codigo, y mostrara paso a paso el desarrollo del modelo con el uso del framework.\n",
        "\n",
        "Para mas informacion de este proyecto, utiliza la liga del repositorio: https://github.com/lordschipper5/TC3006C.101-Portafolio-A01720253.git\n",
        "\n",
        "Para este proceso se utilizaran archivos que fueron modificados con el proceso de ETL, este proceso se puede encontrar en: https://github.com/ArturoGarzaTec/TC3006C.101_Equipo.git\n",
        "\n",
        "El archivo que estaremos utilizando del ETL se **llama train_transformed**.\n",
        "\n",
        "Para los resultados, se hizo un split de los resultados con los datos de entrenamiento. Estos estaran incluidos en el archivo de\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "Registros: 891\n",
        "\n",
        "Caracterisitcas: 6\n",
        "Pclass, Age, Sex, Fam \"Cant de Familia\", Fare, y Embarked.\n",
        "\n",
        "Clases: 1 \"Sobrevivio\", 0 \"No sobrevivio\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IzLGMp3RytqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIJVP_-uytCt",
        "outputId": "7efe820a-a1bf-4f82-a204-0cea1eadd33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parametros: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Mejor precision: 0.8282322580645161\n",
            "Precision sin configuracion: 80.60%\n",
            "     Valores Input  Valores Output\n",
            "709              1               1\n",
            "439              0               0\n",
            "840              0               0\n",
            "720              1               1\n",
            "39               1               1\n",
            "..             ...             ...\n",
            "821              1               0\n",
            "633              0               0\n",
            "456              0               0\n",
            "500              0               0\n",
            "430              1               0\n",
            "\n",
            "[268 rows x 2 columns]\n",
            "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
            " 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
            " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 1 1 1 1 0 0 0 0 0]\n",
            "Ejemplo 1 - Prediccion: 1\n",
            "Ejemplo 2 - Prediccion: 0\n",
            "Ejemplo 3 - Prediccion: 1\n",
            "Precision: 0.8041237113402062\n",
            "Exactitud: 0.8059701492537313\n",
            "Matriz de Confusion:\n",
            "[[138  19]\n",
            " [ 33  78]]\n",
            "Exhaustividad (Recall): 0.7027027027027027\n",
            "F1-score: 0.7499999999999999\n",
            "Soporte (Cantidad de muestras de prueba): 268\n"
          ]
        }
      ],
      "source": [
        "#Importacion de librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,  GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Cargamos el archivo, utiliza otro ruteo en caso de almacenar el archivo en otro lado\n",
        "data = pd.read_csv('train_transformed.csv')\n",
        "\n",
        "# Separamos survived\n",
        "X = data.drop(['Survived'], axis=1)\n",
        "y = data['Survived']\n",
        "\n",
        "# Dividimos los datos para tener un conjunto de entrenamiento y otro de prueba\n",
        "X_train, X_prueba, y_train, y_prueba = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear el modelo Random Forest\n",
        "modeloRandomForest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definimos parametros a probar para encontrar una mejor configuracion\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 70, 100, 200], #Cant Arboles\n",
        "    'max_depth': [2, 10, 20], #Profunidad de Arbol\n",
        "    'min_samples_split': [2, 5, 10, 20] #cant muestras\n",
        "}\n",
        "\n",
        "# Definimos R al cuadrado\n",
        "scorer = make_scorer(accuracy_score)\n",
        "\n",
        "# Realizamos una busqueda de hiperparametros con gridSearch de sklearn\n",
        "grid_search = GridSearchCV(modeloRandomForest, param_grid, scoring=scorer, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtenemos los mejores parametros\n",
        "params_optimo = grid_search.best_params_\n",
        "precision_optima = grid_search.best_score_\n",
        "\n",
        "print(\"Mejores parametros:\", params_optimo)\n",
        "print(\"Mejor precision:\", precision_optima)\n",
        "\n",
        "# Entrenamos el modelo con los mejores parametros obtenidos\n",
        "modeloRandomForestConf = RandomForestClassifier(**params_optimo, random_state=42)\n",
        "modeloRandomForestConf.fit(X_train, y_train)\n",
        "\n",
        "# Predecir los valores de los datos prueba\n",
        "y_pred = modeloRandomForestConf.predict(X_prueba)\n",
        "\n",
        "# Calculamos la precision del modelo\n",
        "precision = accuracy_score(y_prueba, y_pred)\n",
        "print(\"Precision sin configuracion: {:.2f}%\".format(precision * 100))\n",
        "\n",
        "# Crear un DataFrame donde se compara los valores iniciales con los resultados\n",
        "resultados_df = pd.DataFrame({'Valores Input': y_prueba, 'Valores Output': y_pred})\n",
        "print(resultados_df)\n",
        "\n",
        "# Guardamos el DataFrame en un archivo CSV\n",
        "resultados_df.to_csv('predicciones.csv', index=False)\n",
        "\n",
        "# Predecir los valores de los datos de prueba utilizando el modelo entrenado\n",
        "predicciones_realizadas = modeloRandomForestConf.predict(X_prueba)\n",
        "\n",
        "# Ahora, 'predicciones_realizadas' contiene las predicciones del modelo para los datos de prueba con de acuerdo al arreglo principal del split\n",
        "print(predicciones_realizadas)\n",
        "\n",
        "# Otras 3 predicciones sin archivo\n",
        "# Datos de entrada para tres ejemplos\n",
        "# Pclass, Age, Sex, Fam, Fare, Embarked\n",
        "# Datos de entrada para el primer ejemplo\n",
        "ejemplo1 = [3, 25, 0, 1, 4, 1]\n",
        "\n",
        "# Convertir los datos de entrada en un DataFrame\n",
        "ejemplo1_df = pd.DataFrame([ejemplo1], columns=X_train.columns)\n",
        "\n",
        "# Predecir la supervivencia utilizando el modelo entrenado\n",
        "prediccion_ejemplo1 = modeloRandomForestConf.predict(ejemplo1_df)\n",
        "\n",
        "# Imprimir la prediccion\n",
        "print(\"Ejemplo 1 - Prediccion:\", prediccion_ejemplo1[0])\n",
        "\n",
        "ejemplo2 = [2, 28, 1, 4, 4, 2]\n",
        "\n",
        "# Convertir los datos de entrada en un DataFrame\n",
        "ejemplo2_df = pd.DataFrame([ejemplo2], columns=X_train.columns)\n",
        "\n",
        "# Predecir la supervivencia utilizando el modelo entrenado\n",
        "prediccion_ejemplo2 = modeloRandomForestConf.predict(ejemplo2_df)\n",
        "\n",
        "# Imprimir la prediccion\n",
        "print(\"Ejemplo 2 - Prediccion:\", prediccion_ejemplo2[0])\n",
        "\n",
        "ejemplo3 = [1, 22, 0, 2, 3, 2]\n",
        "\n",
        "# Convertir los datos de entrada en un DataFrame\n",
        "ejemplo3_df = pd.DataFrame([ejemplo3], columns=X_train.columns)\n",
        "\n",
        "# Predecir la supervivencia utilizando el modelo entrenado\n",
        "prediccion_ejemplo3 = modeloRandomForestConf.predict(ejemplo3_df)\n",
        "\n",
        "# Imprimir la prediccion\n",
        "print(\"Ejemplo 3 - Prediccion:\", prediccion_ejemplo3[0])\n",
        "\n",
        "\n",
        "#Evaluacion con metricas\n",
        "# Precision\n",
        "precision = accuracy_score(y_prueba, y_pred)\n",
        "\n",
        "# Otra forma de calcular la precisión (exactitud)\n",
        "exactitud = modeloRandomForestConf.score(X_prueba, y_prueba)\n",
        "\n",
        "# Matriz de confusion\n",
        "matriz_confusion = confusion_matrix(y_prueba, y_pred)\n",
        "\n",
        "# Precision, exhaustividad, F1-score y soporte\n",
        "precision = precision_score(y_prueba, y_pred)\n",
        "exhaustividad = recall_score(y_prueba, y_pred)\n",
        "f1 = f1_score(y_prueba, y_pred)\n",
        "soporte = len(y_prueba)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Exactitud:\", exactitud)\n",
        "print(\"Matriz de Confusion:\")\n",
        "print(matriz_confusion)\n",
        "print(\"Exhaustividad (Recall):\", exhaustividad)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Soporte (Cantidad de muestras de prueba):\", soporte)\n"
      ]
    }
  ]
}